{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4e429df",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read data: vectors and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d3bdf4-9b88-4008-93e6-5e6f656e5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a03c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab73773",
   "metadata": {},
   "source": [
    "# MNIST, USPS and Pendigits are easy\n",
    "\n",
    "We can use the sklearn API to fetch data for the Pendigits, MNIST and USPS datasets.\n",
    "\n",
    "Of these datasets pendigits is the smallest, with only 1797 samples, and is only 64 dimensional. This makes a good first dataset to test things out on -- the dataset is small enough that practically anything should be able to run on this efficiently.\n",
    "\n",
    "USPS provides a slightly more challenging dataset, with almost 10,000 samples and 256 dimensions, but is still samall enough to be tractable for even naive clustering implementations.\n",
    "\n",
    "MNIST provides a good basic scaling test with 70,000 samples in 784 dimensions. In practice this is not a very large dataset compared to many that people want to cluster, although the dimensionality may provide some challenges.\n",
    "\n",
    "# Buildings and COIL are harder\n",
    "\n",
    "The buildings and COIL-29 datasets provide some slightly more challenging image based problems, with more complex images to be dealt with. Both are still small in number of samples, so should be easily tractable. COIL *should* be relatively easy to cluster since the different classes should provide fairly tight and distinct clusters (being 72 images of the same object from different angles for each class). The buildings dataset, which has colour images from many angles and different lighting conditions, should be a much more challenging problem to cluster if using simple euclidean distance on the flattened vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69298d-6019-464b-b42c-7fa127db5b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_list = ['pendigits', 'coil', 'mnist', 'usps', 'buildings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaddb16-52e0-45fc-839c-7c34c4b9b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pendigits(data_folder = '../data'):\n",
    "    from sklearn.datasets import load_digits\n",
    "    digits = load_digits()\n",
    "    raw_data = np.asarray(digits.data.astype(np.float32))\n",
    "    labels = np.asarray(digits.target) \n",
    "    return(raw_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e2081-7b8c-4ffd-af05-6851c2b9feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_coil(data_folder = '../data'):\n",
    "    import re\n",
    "    import zipfile\n",
    "    import imageio.v2 as imageio\n",
    "    images_zip = zipfile.ZipFile(f'{data_folder}/coil20.zip')\n",
    "    mylist = images_zip.namelist()\n",
    "    r = re.compile(\".*\\.png$\")\n",
    "    filelist = list(filter(r.match, mylist))\n",
    "    images_zip.extractall(data_folder + '/.')\n",
    "    \n",
    "    coil_feature_vectors = []\n",
    "    for filename in filelist:\n",
    "        im = imageio.imread(data_folder + '/' + filename)\n",
    "        coil_feature_vectors.append(im.flatten())\n",
    "    coil_20_data = np.asarray(coil_feature_vectors)\n",
    "    coil_20_target = pd.Series(filelist).str.extract(\"obj([0-9]+)\", expand=False).values.astype(np.int32)\n",
    "    \n",
    "    raw_coil = coil_20_data.astype(np.float32)\n",
    "    return(raw_coil, coil_20_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42937552-3262-462a-a658-d9e7096aa6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mnist(data_folder = '../data'):\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml(\"MNIST_784\")\n",
    "    raw_mnist = np.asarray(mnist.data.astype(np.float32))\n",
    "    targets = np.array(mnist.target.astype('int'))\n",
    "    return(raw_mnist, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d342c4-9d88-4d25-8287-9493adc7ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_usps(data_folder = '../data'):\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    usps = fetch_openml(\"USPS\", version=2)\n",
    "    raw_usps = np.asarray(usps.data.astype(np.float32))\n",
    "    targets = np.array(usps.target.astype('int'))\n",
    "    return(raw_usps, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ccfcd-68b1-480f-a314-4c1b3864e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_buildings(data_folder = '../data'):\n",
    "    from glob import glob\n",
    "    from PIL import Image\n",
    "    buildings_data = []\n",
    "    buildings_target = []\n",
    "    for i in range(1, 41):\n",
    "        directory = f\"{data_folder}/sheffield_buildings/Dataset/{i}\"\n",
    "        images = np.vstack([np.asarray(Image.open(filename).resize((96, 96))).flatten() for filename in glob(f\"{directory}/*\")])\n",
    "        labels = np.full(len(glob(f\"{directory}/*\")), i, dtype=np.int32)\n",
    "        buildings_data.append(images)\n",
    "        buildings_target.append(labels)\n",
    "    buildings_data = np.vstack(buildings_data)\n",
    "    buildings_target = np.hstack(buildings_target)\n",
    "    return(buildings_data, buildings_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465c645e-b96a-40d9-b754-918aa3c5eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_id_name(dataset_id=-1, dataset_name=None, data_set_list=data_set_list):\n",
    "    n = len(data_set_list)\n",
    "    if(dataset_name is None and dataset_id == -1):\n",
    "        raise ValueError('Need to define dataset_name or dataset_id')\n",
    "    if(dataset_name is None):\n",
    "        if(dataset_id not in list(range(n))):\n",
    "            raise ValueError(f'dataset_id must an integer be between 0 and {n-1}')\n",
    "        else:\n",
    "            dataset_name = data_set_list[dataset_id]\n",
    "    if(dataset_id == -1 and dataset_name not in data_set_list):\n",
    "        raise ValueError(f'dataset_name must be in {data_set_list}')\n",
    "    else:\n",
    "        dataset_id = data_set_list.index(dataset_name)\n",
    "    return(dataset_id, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00db09-939a-4e30-a76b-747c1740a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(dataset_id, data_folder = '../data'):\n",
    "    if(dataset_id == 0):\n",
    "        raw_data, labels = read_pendigits(data_folder)\n",
    "\n",
    "    if(dataset_id==1):\n",
    "        raw_data, labels = read_coil(data_folder)\n",
    "\n",
    "    if(dataset_id==2):\n",
    "        raw_data, labels = read_mnist(data_folder)\n",
    "\n",
    "    if(dataset_id==3):\n",
    "        raw_data, labels = read_usps(data_folder)\n",
    "\n",
    "    if(dataset_id==4):\n",
    "        raw_data, labels = read_buildings(data_folder)\n",
    "        \n",
    "    return(raw_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b863b01-eece-4348-8749-f6b9f68ad574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset_id=-1, dataset_name=None, data_set_list=data_set_list, top_n=None, data_folder = '../data'):\n",
    "    dataset_id, dataset_name = map_id_name(dataset_id, dataset_name)\n",
    "    print(dataset_name)\n",
    "        \n",
    "    raw_data, labels = read(dataset_id, data_folder)\n",
    "    \n",
    "    if(raw_data.shape[0] != len(labels)): \n",
    "        raise ValueError(f'data and labels of different lengths {raw_data.shape[0]} and {len(labels)}')\n",
    "    if(top_n is not None and top_n < len(labels)):\n",
    "        raw_data = raw_data[:top_n]\n",
    "        labels = labels[:top_n]\n",
    "    return(raw_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7227fb-0362-498f-81a5-37a97832a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could set set_op_mix_ratio=0.0 to get a pure fuzzy intersection - similar to the exploration of bi-directional edges in graphs\n",
    "# graph_type is 'nx' or 'ig' to designate Networkx or iGraph respectively.\n",
    "\n",
    "def get_umap_graph(raw_data=None, dataset_id=-1, dataset_name=None, return_all=False, set_op_mix_ratio=1.0, graph_type='ig'):\n",
    "    import umap\n",
    "    dataset_id, dataset_name = map_id_name(dataset_id, dataset_name)\n",
    "    if(raw_data is None):\n",
    "        raw_data, targets = get_dataset(dataset_id)\n",
    "    \n",
    "    # pendigits\n",
    "    if(dataset_id == 0):\n",
    "        A, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(X=raw_data, \n",
    "                                                         n_neighbors=15, \n",
    "                                                         random_state=0, \n",
    "                                                         metric='euclidean', \n",
    "                                                         return_dists=True,\n",
    "                                                        set_op_mix_ratio=set_op_mix_ratio)\n",
    "    # coil\n",
    "    if(dataset_id == 1):\n",
    "        A, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(X=raw_data,\n",
    "                                                            n_neighbors=5,  \n",
    "                                                            random_state=0, \n",
    "                                                         metric='euclidean', \n",
    "                                                         return_dists=True,\n",
    "                                                        set_op_mix_ratio=set_op_mix_ratio)\n",
    "    # mnist\n",
    "    if(dataset_id == 2):\n",
    "        A, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(X=raw_data,\n",
    "                                                            n_neighbors=10,  \n",
    "                                                            random_state=42, \n",
    "                                                         metric='euclidean', \n",
    "                                                         return_dists=True,\n",
    "                                                         set_op_mix_ratio=set_op_mix_ratio)\n",
    "    # usps\n",
    "    if(dataset_id == 3):\n",
    "        A, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(X=raw_data,\n",
    "                                                            n_neighbors=10,  \n",
    "                                                            random_state=42, \n",
    "                                                         metric='euclidean', \n",
    "                                                         return_dists=True,\n",
    "                                                         set_op_mix_ratio=set_op_mix_ratio)\n",
    "    # buildings    \n",
    "    if(dataset_id == 4):\n",
    "        A, sigmas, rhos, dists = umap.umap_.fuzzy_simplicial_set(X=raw_data,\n",
    "                                                            n_neighbors=8,  \n",
    "                                                            random_state=42, \n",
    "                                                         metric='euclidean', \n",
    "                                                         return_dists=True,\n",
    "                                                        set_op_mix_ratio=set_op_mix_ratio)\n",
    "    if(graph_type=='nx'):\n",
    "        G = nx.from_scipy_sparse_matrix(A, edge_attribute='weight')\n",
    "    else:\n",
    "        G = ig.Graph.Weighted_Adjacency(A)\n",
    "    if(return_all):\n",
    "        return(G, A, sigmas, rhos, dists)\n",
    "    else:\n",
    "        return(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8aac5-de14-450e-b205-0ab164af9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_umap_vectors(dataset_id=-1, dataset_name=None):\n",
    "    import umap\n",
    "    dataset_id, dataset_name = map_id_name(dataset_id, dataset_name)\n",
    "    if(raw_data is None):\n",
    "        raw_data, targets = get_dataset(dataset_id)\n",
    "    \n",
    "    # pendigits\n",
    "    if(dataset_id == 0):\n",
    "        umap_rep = umap.UMAP(n_neighbors=15,n_components=4, min_dist=1e-8, random_state=0).fit_transform(raw_data)\n",
    "\n",
    "    # coil\n",
    "    if(dataset_id == 1):\n",
    "        umap_rep = umap.UMAP(n_neighbors=5, n_components=4, min_dist=1e-8, random_state=0, n_epochs=1000).fit_transform(raw_data)\n",
    "    \n",
    "    # mnist\n",
    "    if(dataset_id == 2):\n",
    "        umap_rep = umap.UMAP(n_neighbors=10, n_components=4, min_dist=1e-8, random_state=42, n_epochs=500).fit_transform(raw_data)\n",
    "\n",
    "    # usps    \n",
    "    if(dataset_id == 3):\n",
    "        umap_rep = umap.UMAP(n_neighbors=10, n_components=4, min_dist=1e-8, random_state=42, n_epochs=500).fit_transform(raw_data)\n",
    "\n",
    "    # buildings    \n",
    "    if(dataset_id == 4):\n",
    "        umap_rep = umap.UMAP(n_neighbors=8, n_components=4, min_dist=1e-8, random_state=42, n_epochs=1000).fit_transform(raw_data)\n",
    "    \n",
    "    return(umap_rep)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-high-dim-easydata]",
   "language": "python",
   "name": "conda-env-.conda-high-dim-easydata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
